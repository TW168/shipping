{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize connection.\n",
    "# Uses st.cache_resource to only run once.\n",
    "@st.cache_resource\n",
    "def init_connection():\n",
    "    return mysql.connector.connect(**st.secrets[\"db3_db\"])\n",
    "\n",
    "conn= init_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  Site BL_Number Truck_Appointment_Date  BL_Weight  Freight_Amount  \\\n",
      "0        1  AMAZ   WZ1A645                   None     1202.0            0.00   \n",
      "1        2  AMAZ   WZ1B035                   None    11688.0            0.00   \n",
      "2        3  AMAZ   WZ2A056                   None    11110.0            0.00   \n",
      "3        4  AMAZ   WZ2A056                   None    11110.0            0.00   \n",
      "4        5  AMAZ   WZ2A390                   None    22232.0            0.00   \n",
      "...    ...   ...       ...                    ...        ...             ...   \n",
      "3031  3032  VAMT   2065349             2023-02-27    22126.8         1875.74   \n",
      "3032  3033  VAMT   2065349             2023-02-27    22126.8         1875.74   \n",
      "3033  3034  VAMT   2065349             2023-02-27    22126.8         1875.74   \n",
      "3034  3035  VAMT   2065349             2023-02-27    22126.8         1875.74   \n",
      "3035  3036  VAMT   2065350                   None    27802.1            0.00   \n",
      "\n",
      "     Truck_Appt_Time Pickup_Date State    Ship_to_City  ... Waybill_Number  \\\n",
      "0                NaT  2023-02-15    UT  SALT LAKE CITY  ...           None   \n",
      "1                NaT  2023-02-13    WA          BLAINE  ...           None   \n",
      "2                NaT  2023-02-03    CA         FREMONT  ...           None   \n",
      "3                NaT  2023-02-22    CA         FREMONT  ...           None   \n",
      "4                NaT  2023-02-13    CO   COMMERCE CITY  ...           None   \n",
      "...              ...         ...   ...             ...  ...            ...   \n",
      "3031             NaT  2023-02-20    PA            YORK  ...        5264206   \n",
      "3032             NaT  2023-02-20    PA            YORK  ...        5264206   \n",
      "3033             NaT  2023-02-20    PA            YORK  ...        5264206   \n",
      "3034             NaT  2023-02-20    PA            YORK  ...        5264206   \n",
      "3035             NaT  2023-02-17    IN      GREENFIELD  ...           None   \n",
      "\n",
      "     Sales_Code Transportation_Code Transaction_Type Product_Group  \\\n",
      "0          SWCK                   T               RS            SW   \n",
      "1          SWZU                   T               RS            SW   \n",
      "2          SWBE                   T               RS            SW   \n",
      "3          SWBE                   T               RS            SW   \n",
      "4          SWCK                   T               RS            SW   \n",
      "...         ...                 ...              ...           ...   \n",
      "3031       CFGF                   T               SX            BP   \n",
      "3032       CFGF                   T               SX            BP   \n",
      "3033       CFGF                   T               SX            BP   \n",
      "3034       CFGF                   T               SX            BP   \n",
      "3035       CFTO                   T               RS            BP   \n",
      "\n",
      "      uploaded_date_time rpt_run_date    rpt_run_time  \\\n",
      "0    2023-02-25 14:58:51   2023-02-24 0 days 16:00:00   \n",
      "1    2023-02-25 14:58:51   2023-02-24 0 days 16:00:00   \n",
      "2    2023-02-25 14:58:51   2023-02-24 0 days 16:00:00   \n",
      "3    2023-02-25 14:58:51   2023-02-24 0 days 16:00:00   \n",
      "4    2023-02-25 14:58:51   2023-02-24 0 days 16:00:00   \n",
      "...                  ...          ...             ...   \n",
      "3031 2023-02-25 15:07:40   2023-02-20 0 days 16:00:00   \n",
      "3032 2023-02-25 15:07:40   2023-02-20 0 days 16:00:00   \n",
      "3033 2023-02-25 15:07:40   2023-02-20 0 days 16:00:00   \n",
      "3034 2023-02-25 15:07:40   2023-02-20 0 days 16:00:00   \n",
      "3035 2023-02-25 15:07:40   2023-02-20 0 days 16:00:00   \n",
      "\n",
      "                                              file_name  file_size  \n",
      "0     AmTopp Current Pickup Detail Report as of 2023...     199553  \n",
      "1     AmTopp Current Pickup Detail Report as of 2023...     199553  \n",
      "2     AmTopp Current Pickup Detail Report as of 2023...     199553  \n",
      "3     AmTopp Current Pickup Detail Report as of 2023...     199553  \n",
      "4     AmTopp Current Pickup Detail Report as of 2023...     199553  \n",
      "...                                                 ...        ...  \n",
      "3031  AmTopp Current Pickup Detail Report as of 2023...     139155  \n",
      "3032  AmTopp Current Pickup Detail Report as of 2023...     139155  \n",
      "3033  AmTopp Current Pickup Detail Report as of 2023...     139155  \n",
      "3034  AmTopp Current Pickup Detail Report as of 2023...     139155  \n",
      "3035  AmTopp Current Pickup Detail Report as of 2023...     139155  \n",
      "\n",
      "[3036 rows x 36 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tonyw\\AppData\\Local\\Temp\\ipykernel_29616\\394485314.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  query =pd.read_sql('select * from ipg_ez', conn)\n"
     ]
    }
   ],
   "source": [
    "query =pd.read_sql('select * from ipg_ez', conn)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to MYSQL database: ws_hub\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30844"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload uscities to db\n",
    "import pandas as pd \n",
    "from helper import connect_to_database\n",
    "\n",
    "df = pd.read_excel('uscities.xlsx')\n",
    "\n",
    "conn = connect_to_database('ws_hub_db')\n",
    "\n",
    "df.to_sql('us_cities', con=conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to MYSQL database: db3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30844"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SITE', 'B/L Number', 'Truck Appointment Date (YY/MM/DD)',\n",
       "       'B/L Weight (LB)', 'Freight Amount ($)', 'Truck Appt. Time',\n",
       "       'PickUp Date (YY/MM/DD)', 'State', 'Ship to City', 'Ship to Customer',\n",
       "       'Order Number', 'Order Item', 'CSR', 'Freight Term',\n",
       "       'Require Date (YY/MM/DD)', 'Schedule Date (YY/MM/DD)',\n",
       "       'Unshipped Weight (Lb)', 'Product Code', 'Pick Weight (Lb)',\n",
       "       'Number of Pallet', 'Pickup By', 'Change Date (YY/MM/DD)', 'Carrier ID',\n",
       "       'Arrange By', 'Unit Freight (cent/Lb)', 'Waybill Number', 'Sales Code',\n",
       "       'Transportation Code', 'Transaction Type', 'Product Group',\n",
       "       'Report run at 2023-2-24 H9M0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(r\"C:\\Users\\tonyw\\Downloads\\AmTopp Current Pickup Detail Report as of 2023-2-24 H9M0.xlsx\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1=\"AmTopp Current Pickup Detail Report as of 2023-2-24 H9M0\" \n",
    "len(file1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpt_date is not Friday, so truck_date is 2022-03-04\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# Replace with your actual rpt_date value\n",
    "rpt_date_str = '2022-03-03'\n",
    "\n",
    "# Convert rpt_date string to a datetime.date object\n",
    "rpt_date = st.date_input(\"Choose a date: \")\n",
    "# Check if rpt_date is a Friday\n",
    "if rpt_date.weekday() == 4: # Friday is the 4th day of the week\n",
    "    truck_date = rpt_date + datetime.timedelta(days=1) # Add one day to rpt_date\n",
    "    truck_date_str = truck_date.strftime('%Y-%m-%d')\n",
    "    saturday_str = (truck_date + datetime.timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    sunday_str = (truck_date + datetime.timedelta(days=2)).strftime('%Y-%m-%d')\n",
    "    monday_str = (truck_date + datetime.timedelta(days=3)).strftime('%Y-%m-%d')\n",
    "    print(f\"rpt_date is Friday, so truck_date is {truck_date_str} (including Saturday, Sunday, and Monday)\")\n",
    "    print(f\"Saturday: {saturday_str}\")\n",
    "    print(f\"Sunday: {sunday_str}\")\n",
    "    print(f\"Monday: {monday_str}\")\n",
    "else:\n",
    "    truck_date = rpt_date + datetime.timedelta(days=1) # Add one day to rpt_date\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to MYSQL database: db3\n",
      "Successfully connected to MYSQL database: db3\n"
     ]
    },
    {
     "ename": "ObjectNotExecutableError",
     "evalue": "Not an executable object:    Site Product_Group       WGT    PLT\n0  AMJK            SW  545770.0  470.0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\tonyw\\Documents\\dev\\shipping\\shipping\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1374\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1374\u001b[0m     meth \u001b[39m=\u001b[39m statement\u001b[39m.\u001b[39;49m_execute_on_connection\n\u001b[0;32m   1375\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\tonyw\\Documents\\dev\\shipping\\shipping\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5901\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[1;32m-> 5902\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute '_execute_on_connection'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mObjectNotExecutableError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m conn\u001b[39m=\u001b[39m connect_to_database(DB)\n\u001b[0;32m      6\u001b[0m qry \u001b[39m=\u001b[39m avail_to_ship_AM(site\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAMJK\u001b[39m\u001b[39m'\u001b[39m, group\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSW\u001b[39m\u001b[39m'\u001b[39m, rpt_date\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m2023-02-24\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m df\u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_sql_query(qry, conn)\n\u001b[0;32m      9\u001b[0m df\n",
      "File \u001b[1;32mc:\\Users\\tonyw\\Documents\\dev\\shipping\\shipping\\venv\\Lib\\site-packages\\pandas\\io\\sql.py:397\u001b[0m, in \u001b[0;36mread_sql_query\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[39mRead SQL query into a DataFrame.\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[39mparameter will be converted to UTC.\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    396\u001b[0m pandas_sql \u001b[39m=\u001b[39m pandasSQL_builder(con)\n\u001b[1;32m--> 397\u001b[0m \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39;49mread_query(\n\u001b[0;32m    398\u001b[0m     sql,\n\u001b[0;32m    399\u001b[0m     index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[0;32m    400\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    401\u001b[0m     coerce_float\u001b[39m=\u001b[39;49mcoerce_float,\n\u001b[0;32m    402\u001b[0m     parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[0;32m    403\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m    404\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    405\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\tonyw\\Documents\\dev\\shipping\\shipping\\venv\\Lib\\site-packages\\pandas\\io\\sql.py:1560\u001b[0m, in \u001b[0;36mSQLDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype)\u001b[0m\n\u001b[0;32m   1512\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m \u001b[39mRead SQL query into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \n\u001b[0;32m   1557\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m args \u001b[39m=\u001b[39m _convert_params(sql, params)\n\u001b[1;32m-> 1560\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m   1561\u001b[0m columns \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mkeys()\n\u001b[0;32m   1563\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\tonyw\\Documents\\dev\\shipping\\shipping\\venv\\Lib\\site-packages\\pandas\\io\\sql.py:1405\u001b[0m, in \u001b[0;36mSQLDatabase.execute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1403\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexecute\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1404\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Simple passthrough to SQLAlchemy connectable\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1405\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnectable\u001b[39m.\u001b[39;49mexecution_options()\u001b[39m.\u001b[39;49mexecute(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tonyw\\Documents\\dev\\shipping\\shipping\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1376\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     meth \u001b[39m=\u001b[39m statement\u001b[39m.\u001b[39m_execute_on_connection\n\u001b[0;32m   1375\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 1376\u001b[0m     util\u001b[39m.\u001b[39;49mraise_(\n\u001b[0;32m   1377\u001b[0m         exc\u001b[39m.\u001b[39;49mObjectNotExecutableError(statement), replace_context\u001b[39m=\u001b[39;49merr\n\u001b[0;32m   1378\u001b[0m     )\n\u001b[0;32m   1379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1380\u001b[0m     \u001b[39mreturn\u001b[39;00m meth(\u001b[39mself\u001b[39m, multiparams, params, _EMPTY_EXECUTION_OPTS)\n",
      "File \u001b[1;32mc:\\Users\\tonyw\\Documents\\dev\\shipping\\shipping\\venv\\Lib\\site-packages\\sqlalchemy\\util\\compat.py:211\u001b[0m, in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    208\u001b[0m     exception\u001b[39m.\u001b[39m__cause__ \u001b[39m=\u001b[39m replace_context\n\u001b[0;32m    210\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 211\u001b[0m     \u001b[39mraise\u001b[39;00m exception\n\u001b[0;32m    212\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# credit to\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "\u001b[1;31mObjectNotExecutableError\u001b[0m: Not an executable object:    Site Product_Group       WGT    PLT\n0  AMJK            SW  545770.0  470.0"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from helper import avail_to_ship, connect_to_database, avail_to_ship_AM\n",
    "\n",
    "DB = 'db3_db'\n",
    "conn= connect_to_database(DB)\n",
    "qry = avail_to_ship_AM(site='AMJK', group='SW', rpt_date='2023-02-24')\n",
    "df= pd.read_sql_query(qry, conn)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f45fa9922e5774a14b98c69ad8c918393caec1b598246a4187c12b4495d4e66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
